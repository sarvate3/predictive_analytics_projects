{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter \n",
    "\n",
    "train = pd.read_json('train.json')\n",
    "\n",
    "ingredients = train['ingredients'].reset_index(drop=True)\n",
    "cuisine_type = list(set(train['cuisine']))\n",
    "common_ing_dict = {'cuisine':[], 'topN': []}\n",
    "\n",
    "# Extract top N most common words from each cuisine type to use as features\n",
    "N = 200\n",
    "\n",
    "for cuisine in cuisine_type:\n",
    "        \n",
    "    word_list = []    \n",
    "    a = train[train['cuisine']==cuisine].reset_index()['ingredients']\n",
    " \n",
    "    combined_str = \"\"\n",
    "\n",
    "    for i in a:\n",
    "        word_list = word_list + i\n",
    "\n",
    "# The following lines of code are used to examine word by word:\n",
    "#         combined_str = (combined_str + \" \" + word_list[len(word_list)-1]).lower()    \n",
    "#     word_list = combined_str.split()\n",
    "    \n",
    "    word_count = Counter(word_list)\n",
    "    word_freq_table = pd.DataFrame({'word':list(word_count.keys()), 'count':list(word_count.values())})\n",
    "    word_freq_table = word_freq_table.sort_values(by=['count'], ascending=False)\n",
    "    \n",
    "    common_ing_dict['cuisine'].append(type)\n",
    "    common_ing_dict['topN'].append(list(word_freq_table['word'][0:N]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ing_df = pd.DataFrame({'cuisine':common_ing_dict['cuisine'],'topN':common_ing_dict['topN']})\n",
    "\n",
    "# List of unique words from compiling top N most common ingredients from each cuisine\n",
    "feature_words = list(set(sum(common_ing_df['topN'], [])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 10,000 unique pair samples from randomly chosen recipes in cuisine category\n",
    "# Count occurrences of each pair in all recipes and sort by frequency\n",
    "\n",
    "top_pair_features = []\n",
    "\n",
    "for cuisine in cuisine_type:\n",
    "    \n",
    "    a = train[train['cuisine']=='greek']['ingredients']\n",
    "    a = a.reset_index()['ingredients']\n",
    "\n",
    "    combined_str = \"\" \n",
    "    str_list = []\n",
    "\n",
    "    for i in a:\n",
    "        for j in i:\n",
    "            combined_str = combined_str + j + \" \"\n",
    "        str_list.append(combined_str.split())  \n",
    "        combined_str = \"\"\n",
    "    \n",
    "    length = len(a)-1\n",
    "    \n",
    "    # Number of total random pair samples from dataset\n",
    "    N_samples = 10000\n",
    "    \n",
    "    # Number of pair selections per cuisine type\n",
    "    N_pairs = 10\n",
    "\n",
    "    import random\n",
    "\n",
    "    sample_list = []\n",
    "\n",
    "    sample_pairs = []\n",
    "\n",
    "    for x in range(N_samples):\n",
    "        sample_list.append(random.randint(0,length))\n",
    "\n",
    "    for i in sample_list:\n",
    "        if len(str_list[i]) < 2:\n",
    "            continue\n",
    "        newlist = random.sample(str_list[i],2)\n",
    "        newlist.sort()\n",
    "        if (newlist[0]==newlist[1]):\n",
    "            continue\n",
    "        if newlist in sample_pairs:\n",
    "            continue\n",
    "        else:\n",
    "            sample_pairs.append(newlist)\n",
    "\n",
    "    counter = 0\n",
    "    pair_counts = []\n",
    "\n",
    "    for i in sample_pairs:\n",
    "        for j in a:\n",
    "            if i[0] in j and i[1] in j:\n",
    "                counter = counter + 1\n",
    "        pair_counts.append(counter)\n",
    "        counter = 0\n",
    "\n",
    "    top_pairs = pd.DataFrame({'pairs':sample_pairs,'count':pair_counts}).sort_values(by=['count'], ascending=False)\n",
    "    top_pairs = top_pairs.reset_index()['pairs'][0:N_pairs]\n",
    "\n",
    "    for i in top_pairs:\n",
    "        if i in top_pair_features:\n",
    "            continue\n",
    "        else:\n",
    "            top_pair_features.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Secondary features cutoff\n",
    "N_sec = 200\n",
    "\n",
    "recipe_data = {'cuisine':[], 'primary_features':[], 'secondary_features':[]}\n",
    "\n",
    "for j in range(0,len(train['ingredients'])):\n",
    "    test = []\n",
    "    for i in feature_words:\n",
    "        if i in train['ingredients'][j]:\n",
    "            test.append(1)\n",
    "        else:\n",
    "            test.append(0)\n",
    "    recipe_data['cuisine'].append(train['cuisine'][j])\n",
    "    recipe_data['primary_features'].append(test)\n",
    "    \n",
    "for j in range(0,len(train['ingredients'])):\n",
    "    test = []\n",
    "    for i in top_pair_features[0:min(N_sec,len(top_pair_features))]:\n",
    "        if i[0] in train['ingredients'][j] and i[1] in train['ingredients'][j]:\n",
    "            test.append(1)\n",
    "        else:\n",
    "            test.append(0)\n",
    "    recipe_data['secondary_features'].append(test)\n",
    "    \n",
    "data = (np.concatenate([np.array(recipe_data['primary_features']), np.array(recipe_data['secondary_features'])], 1))\n",
    "\n",
    "target = []\n",
    "\n",
    "labels = pd.Series(recipe_data['cuisine'])\n",
    "\n",
    "for i in labels:\n",
    "    target.append(cuisine_type.index(i))\n",
    "    \n",
    "target = np.array(target)\n",
    "recipe = {'data':data, 'target':target, 'target_names':cuisine_type}\n",
    "\n",
    "recipe['target'] = recipe['target'][0:39774]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(recipe['data'], recipe['target'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=400, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training score: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Test score: {:.3f}\".format(forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# clf = MLPClassifier(solver='sgd', alpha=1, hidden_layer_sizes=[1000], max_iter=500)\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Training score: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "# print(\"Test score: {:.3f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import tree\n",
    "# import graphviz\n",
    "\n",
    "# clf = tree.DecisionTreeClassifier(max_depth=100, min_samples_split=500)\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Training score: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "# print(\"Test score: {:.3f}\".format(clf.score(X_test, y_test)))\n",
    "\n",
    "# dot_data = tree.export_graphviz(clf, out_file=None, feature_names=feature_words, class_names=recipe['target_names'], \n",
    "#                                 filled=True, rounded=True, special_characters=True)  \n",
    "# graph = graphviz.Source(dot_data)  \n",
    "# graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
