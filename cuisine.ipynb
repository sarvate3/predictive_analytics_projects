{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuisine Type Prediction\n",
    "#### Built using Python version 3.6.5\n",
    "This project is based on the Kaggle competition titled \"What's Cooking?\" (https://www.kaggle.com/c/whats-cooking/data). \n",
    "The dataset contains the full ingredients list of nearly 40,000 recipes. The purpose of the project is to predict which category of cuisine a given recipe belongs to, out of a list of 20 possible types (Korean, Chinese, Moroccan, Japanese, Filipino, Mexican, Southern US, Irish, Thai, Italian, Vietnamese, Jamaican, Indian, British, Russian, Cajun Creole, Greek, French, Brazilian, Spanish). \n",
    "\n",
    "#### Methods\n",
    "\n",
    "This program uses Pandas to extract the information and subsequently builds an array of input features based on most commonly occurring ingredients within each cuisine category, and whether or not a given recipe contains each of those ingredients (a binary indicator). \n",
    "\n",
    "Random forests are the chosen algorithm for this prediction task, because of their generally strong performance in classification tasks, particularly for high-dimensional feature datasets. \n",
    "\n",
    "#### Results Summary\n",
    "\n",
    "Highest Test Set Accuracy Obtained: <b>70.4%</b> <br>\n",
    "\n",
    "Model Type: <b>Random Forest Classifier</b> <br>\n",
    "\n",
    "Hyperparameters: <b>n_estimators (number of trees) = 400</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter \n",
    "\n",
    "# Import downloaded data from JSON file\n",
    "\n",
    "train = pd.read_json('train.json')\n",
    "\n",
    "ingredients = train['ingredients'].reset_index(drop=True)\n",
    "cuisine_type = list(set(train['cuisine']))\n",
    "common_ing_dict = {'cuisine':[], 'topN': []}\n",
    "\n",
    "# Extract top N most common words from each cuisine type to use as features\n",
    "N = 200\n",
    "\n",
    "for cuisine in cuisine_type:\n",
    "        \n",
    "    word_list = []    \n",
    "    a = train[train['cuisine']==cuisine].reset_index()['ingredients']\n",
    " \n",
    "    combined_str = \"\"\n",
    "\n",
    "    for i in a:\n",
    "        word_list = word_list + i\n",
    "\n",
    "# The following lines of code are for alternate method used to examine list word by word:\n",
    "#         combined_str = (combined_str + \" \" + word_list[len(word_list)-1]).lower()    \n",
    "#     word_list = combined_str.split()\n",
    "    \n",
    "    word_count = Counter(word_list)\n",
    "    word_freq_table = pd.DataFrame({'word':list(word_count.keys()), 'count':list(word_count.values())})\n",
    "    word_freq_table = word_freq_table.sort_values(by=['count'], ascending=False)\n",
    "    \n",
    "    common_ing_dict['cuisine'].append(type)\n",
    "    common_ing_dict['topN'].append(list(word_freq_table['word'][0:N]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ing_df = pd.DataFrame({'cuisine':common_ing_dict['cuisine'],'topN':common_ing_dict['topN']})\n",
    "\n",
    "# List of unique words from compiling top N most common ingredients from each cuisine\n",
    "feature_words = list(set(sum(common_ing_df['topN'], [])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note About \"Secondary\" Features:\n",
    "\n",
    "The following section of code was intended to improve the model's test results accuracy by building additional features. This time, the most common pairs of ingredients (i.e. ingredients which appear together in the same recipe with high frequency) were selected for each cuisine type, and the presence or absence of those pairs in a given recipe (binary indicator) became the basis for the \"secondary\" features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 10,000 unique pair samples from randomly chosen recipes in cuisine category\n",
    "# Count occurrences of each pair in all recipes and sort by frequency\n",
    "\n",
    "top_pair_features = []\n",
    "\n",
    "for cuisine in cuisine_type:\n",
    "    \n",
    "    a = train[train['cuisine']=='greek']['ingredients']\n",
    "    a = a.reset_index()['ingredients']\n",
    "\n",
    "    combined_str = \"\" \n",
    "    str_list = []\n",
    "\n",
    "    for i in a:\n",
    "        for j in i:\n",
    "            combined_str = combined_str + j + \" \"\n",
    "        str_list.append(combined_str.split())  \n",
    "        combined_str = \"\"\n",
    "    \n",
    "    length = len(a)-1\n",
    "    \n",
    "    # Number of total random pair samples from dataset\n",
    "    N_samples = 10000\n",
    "    \n",
    "    # Number of pair selections per cuisine type\n",
    "    N_pairs = 10\n",
    "\n",
    "    import random\n",
    "\n",
    "    sample_list = []\n",
    "\n",
    "    sample_pairs = []\n",
    "\n",
    "    for x in range(N_samples):\n",
    "        sample_list.append(random.randint(0,length))\n",
    "\n",
    "    for i in sample_list:\n",
    "        if len(str_list[i]) < 2:\n",
    "            continue\n",
    "        newlist = random.sample(str_list[i],2)\n",
    "        newlist.sort()\n",
    "        if (newlist[0]==newlist[1]):\n",
    "            continue\n",
    "        if newlist in sample_pairs:\n",
    "            continue\n",
    "        else:\n",
    "            sample_pairs.append(newlist)\n",
    "\n",
    "    counter = 0\n",
    "    pair_counts = []\n",
    "\n",
    "    for i in sample_pairs:\n",
    "        for j in a:\n",
    "            if i[0] in j and i[1] in j:\n",
    "                counter = counter + 1\n",
    "        pair_counts.append(counter)\n",
    "        counter = 0\n",
    "\n",
    "    top_pairs = pd.DataFrame({'pairs':sample_pairs,'count':pair_counts}).sort_values(by=['count'], ascending=False)\n",
    "    top_pairs = top_pairs.reset_index()['pairs'][0:N_pairs]\n",
    "\n",
    "    for i in top_pairs:\n",
    "        if i in top_pair_features:\n",
    "            continue\n",
    "        else:\n",
    "            top_pair_features.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Secondary features cutoff\n",
    "\n",
    "N_sec = 200\n",
    "\n",
    "recipe_data = {'cuisine':[], 'primary_features':[], 'secondary_features':[]}\n",
    "\n",
    "for j in range(0,len(train['ingredients'])):\n",
    "    test = []\n",
    "    for i in feature_words:\n",
    "        if i in train['ingredients'][j]:\n",
    "            test.append(1)\n",
    "        else:\n",
    "            test.append(0)\n",
    "    recipe_data['cuisine'].append(train['cuisine'][j])\n",
    "    recipe_data['primary_features'].append(test)\n",
    "    \n",
    "for j in range(0,len(train['ingredients'])):\n",
    "    test = []\n",
    "    for i in top_pair_features[0:min(N_sec,len(top_pair_features))]:\n",
    "        if i[0] in train['ingredients'][j] and i[1] in train['ingredients'][j]:\n",
    "            test.append(1)\n",
    "        else:\n",
    "            test.append(0)\n",
    "    recipe_data['secondary_features'].append(test)\n",
    "    \n",
    "data = (np.concatenate([np.array(recipe_data['primary_features']), np.array(recipe_data['secondary_features'])], 1))\n",
    "\n",
    "target = []\n",
    "\n",
    "labels = pd.Series(recipe_data['cuisine'])\n",
    "\n",
    "for i in labels:\n",
    "    target.append(cuisine_type.index(i))\n",
    "    \n",
    "target = np.array(target)\n",
    "recipe = {'data':data, 'target':target, 'target_names':cuisine_type}\n",
    "\n",
    "recipe['target'] = recipe['target'][0:39774]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(recipe['data'], recipe['target'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.996\n",
      "Test score: 0.704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=400, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training score: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Test score: {:.3f}\".format(forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network classifier method:\n",
    "\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# clf = MLPClassifier(solver='sgd', alpha=1, hidden_layer_sizes=[1000], max_iter=500)\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Training score: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "# print(\"Test score: {:.3f}\".format(clf.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
